{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "500fdd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "dataset/collected_trajectories_v2/constant.zarr\n",
      "/\n",
      " ├── data\n",
      " │   ├── actions (9975546, 19) float32\n",
      " │   ├── clock (9975546, 5, 2) float32\n",
      " │   ├── commands (9975546, 5, 11) float32\n",
      " │   ├── critic_obs (9975546, 321) float32\n",
      " │   ├── dones (9975546,) bool\n",
      " │   ├── proprio (9975546, 5, 63) float32\n",
      " │   ├── rewards (9975546,) float32\n",
      " │   └── root_states (9975546, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command (20000, 11) float32\n",
      "     ├── episode_ends (20000,) int64\n",
      "     └── episode_reward (20000,) float32\n",
      "Rewards, max: 61.48185729980469, min: -13.266547203063965, mean: 43.4718132019043, std: 3.2603378295898438\n",
      "Episode lengths, max: 499, min: 24, mean: 498.7772888644432, std: 8.773650954857128\n",
      "Actions, max: [ 2.400217   2.9353268  3.5993326  6.4726024 14.767946   1.4442703\n",
      "  3.4785094  3.8924353  5.9731183 15.682708   4.7368326  9.729494\n",
      "  2.474783   0.9053369  0.2897315  9.024212   2.9907978  0.6573744\n",
      "  0.6608664]\n",
      "min: [ -1.5382621   -4.1886096   -7.7008653  -13.434552   -11.393337\n",
      "  -2.3249466   -2.395529    -8.125769   -19.974514    -9.600644\n",
      "  -5.9474707   -6.2586894   -2.4599223   -0.66379875  -1.9267869\n",
      "  -5.4059577   -2.408004    -0.8012732   -1.9477473 ]\n",
      "mean: [ 0.07812691  0.01642919 -2.3685079   2.0682688  -0.9275334  -0.06926478\n",
      " -0.03674658 -2.3653836   2.064043   -0.85759634 -0.06913134 -0.23233187\n",
      "  0.08877914  0.01054167 -0.6346575  -0.19719538 -0.10819612  0.00684906\n",
      " -0.6242222 ]\n",
      "std: [0.2825325  0.29551554 0.744737   1.3896297  1.7663835  0.28519598\n",
      " 0.29671824 0.74770576 1.3943396  1.7920215  2.2002776  0.53933567\n",
      " 0.3176717  0.09898898 0.18381715 0.56227195 0.31170112 0.09892019\n",
      " 0.182382  ]\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "/\n",
       " ├── data\n",
       " │   ├── actions (9975546, 19) float32\n",
       " │   ├── clock (9975546, 5, 2) float32\n",
       " │   ├── commands (9975546, 5, 11) float32\n",
       " │   ├── critic_obs (9975546, 321) float32\n",
       " │   ├── dones (9975546,) bool\n",
       " │   ├── proprio (9975546, 5, 63) float32\n",
       " │   ├── rewards (9975546,) float32\n",
       " │   └── root_states (9975546, 13) float32\n",
       " └── meta\n",
       "     ├── episode_command (20000, 11) float32\n",
       "     ├── episode_ends (20000,) int64\n",
       "     └── episode_reward (20000,) float32"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from legged_gym.dataset.replay_buffer import ReplayBuffer\n",
    "import numpy as np\n",
    "\n",
    "def get_rb_structure(rb_path):\n",
    "    print(\"=\"*50)\n",
    "    print(rb_path)\n",
    "    rb = ReplayBuffer.create_from_path(rb_path)\n",
    "    print(rb)\n",
    "    print(f\"Rewards, max: {rb.meta.episode_reward[:].max()}, min: {rb.meta.episode_reward[:].min()}, mean: {rb.meta.episode_reward[:].mean()}, std: {rb.meta.episode_reward[:].std()}\")\n",
    "    ep_ends = rb.meta.episode_ends[:]\n",
    "    ep_lengths = np.diff(ep_ends)\n",
    "    print(f\"Episode lengths, max: {ep_lengths.max()}, min: {ep_lengths.min()}, mean: {ep_lengths.mean()}, std: {ep_lengths.std()}\")\n",
    "    actions = rb.data.actions[:]\n",
    "    print(f\"Actions, max: {np.max(actions, axis=0)}\\nmin: {np.min(actions, axis=0)}\\nmean: {np.mean(actions, axis=0)}\\nstd: {np.std(actions, axis=0)}\")\n",
    "    print(\"=\"*50)\n",
    "    return rb\n",
    "\n",
    "# get_rb_structure(\"dataset/collected_single/switch.zarr\")\n",
    "# get_rb_structure(\"dataset/collected_single/constant.zarr\")\n",
    "# # get_rb_structure(\"dataset/collected_large/switch.zarr\")\n",
    "get_rb_structure(\"dataset/collected_trajectories_v2/constant.zarr\")\n",
    "# # get_rb_structure(\"dataset/collected_single_short/switch.zarr\")\n",
    "# get_rb_structure(\"dataset/new_ds_test/constant.zarr\")\n",
    "# get_rb_structure(\"dataset/collected_trajectories_v2/switch.zarr\")\n",
    "# get_rb_structure(\"dataset/collected_trajectories_v2/constant.zarr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6af8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from legged_gym.dataset.replay_buffer import ReplayBuffer\n",
    "import numpy as np\n",
    "\n",
    "def dataset_process(rb):\n",
    "    data = {key: rb.data[key][:] for key in rb.data.keys()}\n",
    "    meta = {key: rb.meta[key][:] for key in rb.meta.keys()}\n",
    "    new_data = {}\n",
    "    new_data['clock'] = data['clock'][:, -1]\n",
    "    new_data['commands'] = data['commands'][:, -1]\n",
    "    new_data['proprio'] = data['proprio'][:, -1, :44]\n",
    "    new_data['privileged'] = data['critic_obs'][:, -221-24:-221]\n",
    "    new_data['terrain'] = data['critic_obs'][:, -221:]\n",
    "    new_data['actions'] = data['actions']\n",
    "    new_data['rewards'] = data['rewards']\n",
    "    new_data['dones'] = data['dones']\n",
    "    return new_data, meta\n",
    "    \n",
    "\n",
    "def dataset_convert(rb_path):\n",
    "    rb = ReplayBuffer.create_from_path(rb_path)\n",
    "    print(rb)\n",
    "    converted_path = rb_path.replace(\"dataset\", \"converted_dataset\")\n",
    "    if os.path.exists(converted_path):\n",
    "        shutil.rmtree(converted_path)\n",
    "    os.makedirs(converted_path, exist_ok=True)\n",
    "    converted_rb = ReplayBuffer.create_empty_zarr(storage=converted_path)\n",
    "    print(\"Loading data...\")\n",
    "    new_data, new_meta = dataset_process(rb)\n",
    "    print(\"Writing data...\")\n",
    "    converted_rb.add_chunked_data(new_data, target_chunk_bytes=128 * 1024 * 1024)\n",
    "    converted_rb.add_chunked_meta(new_meta, target_chunk_bytes=64 * 1024 * 1024)\n",
    "    print(converted_rb)\n",
    "    assert np.all(converted_rb.data['actions'].shape == rb.data['actions'].shape)\n",
    "    assert np.all(converted_rb.meta['episode_ends'].shape == rb.meta['episode_ends'].shape)\n",
    "    print(\"Conversion completed\")\n",
    "    shutil.rmtree(rb_path)\n",
    "    return rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "baf4fa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      " ├── data\n",
      " │   ├── actions (49970512, 19) float32\n",
      " │   ├── clock (49970512, 5, 2) float32\n",
      " │   ├── commands (49970512, 5, 11) float32\n",
      " │   ├── critic_obs (49970512, 321) float32\n",
      " │   ├── dones (49970512,) bool\n",
      " │   ├── proprio (49970512, 5, 63) float32\n",
      " │   ├── rewards (49970512,) float32\n",
      " │   └── root_states (49970512, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command (100000, 11) float32\n",
      "     ├── episode_ends (100000,) int64\n",
      "     └── episode_reward (100000,) float32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset/collected_single/constant.zarr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[1;32m      2\u001b[0m dataset_convert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/collected_single_short/constant.zarr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m dataset_convert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/collected_trajectories_v2/constant.zarr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[52], line 30\u001b[0m, in \u001b[0;36mdataset_convert\u001b[0;34m(rb_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m converted_rb \u001b[38;5;241m=\u001b[39m ReplayBuffer\u001b[38;5;241m.\u001b[39mcreate_empty_zarr(storage\u001b[38;5;241m=\u001b[39mconverted_path)\n\u001b[1;32m     29\u001b[0m new_data, new_meta \u001b[38;5;241m=\u001b[39m dataset_process(rb)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mconverted_rb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_chunked_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_chunk_bytes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m converted_rb\u001b[38;5;241m.\u001b[39madd_chunked_meta(new_meta, target_chunk_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(converted_rb)\n",
      "File \u001b[0;32m/cpfs/user/caozhe/workspace/HugWBC/legged_gym/dataset/replay_buffer.py:754\u001b[0m, in \u001b[0;36mReplayBuffer.add_chunked_data\u001b[0;34m(self, data, chunks, compressors, target_chunk_bytes)\u001b[0m\n\u001b[1;32m    752\u001b[0m         arr\u001b[38;5;241m.\u001b[39mresize(new_shape, refcheck\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# copy meta\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m \u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py:1497\u001b[0m, in \u001b[0;36mArray.__setitem__\u001b[0;34m(self, selection, value)\u001b[0m\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_orthogonal_selection(pure_selection, value, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_basic_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpure_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py:1593\u001b[0m, in \u001b[0;36mArray.set_basic_selection\u001b[0;34m(self, selection, value, fields)\u001b[0m\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_basic_selection_zd(selection, value, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_basic_selection_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py:1983\u001b[0m, in \u001b[0;36mArray._set_basic_selection_nd\u001b[0;34m(self, selection, value, fields)\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_basic_selection_nd\u001b[39m(\u001b[38;5;28mself\u001b[39m, selection, value, fields\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1978\u001b[0m     \u001b[38;5;66;03m# implementation of __setitem__ for array with at least one dimension\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \n\u001b[1;32m   1980\u001b[0m     \u001b[38;5;66;03m# setup indexer\u001b[39;00m\n\u001b[1;32m   1981\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m BasicIndexer(selection, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1983\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py:2038\u001b[0m, in \u001b[0;36mArray._set_selection\u001b[0;34m(self, indexer, value, fields)\u001b[0m\n\u001b[1;32m   2035\u001b[0m                 chunk_value \u001b[38;5;241m=\u001b[39m chunk_value[item]\n\u001b[1;32m   2037\u001b[0m         \u001b[38;5;66;03m# put data\u001b[39;00m\n\u001b[0;32m-> 2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunk_setitem(chunk_coords, chunk_selection, chunk_value, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[1;32m   2039\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2040\u001b[0m     lchunk_coords, lchunk_selection, lout_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mindexer)\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py:2304\u001b[0m, in \u001b[0;36mArray._chunk_setitem\u001b[0;34m(self, chunk_coords, chunk_selection, value, fields)\u001b[0m\n\u001b[1;32m   2301\u001b[0m     lock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_synchronizer[ckey]\n\u001b[1;32m   2303\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[0;32m-> 2304\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunk_setitem_nosync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py:2308\u001b[0m, in \u001b[0;36mArray._chunk_setitem_nosync\u001b[0;34m(self, chunk_coords, chunk_selection, value, fields)\u001b[0m\n\u001b[1;32m   2306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chunk_setitem_nosync\u001b[39m(\u001b[38;5;28mself\u001b[39m, chunk_coords, chunk_selection, value, fields\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2307\u001b[0m     ckey \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunk_key(chunk_coords)\n\u001b[0;32m-> 2308\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2310\u001b[0m     \u001b[38;5;66;03m# attempt to delete chunk if it only contains the fill value\u001b[39;00m\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_empty_chunks) \u001b[38;5;129;01mand\u001b[39;00m all_equal(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value, cdata):\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py:2334\u001b[0m, in \u001b[0;36mArray._process_for_setitem\u001b[0;34m(self, ckey, chunk_selection, value, fields)\u001b[0m\n\u001b[1;32m   2329\u001b[0m         chunk\u001b[38;5;241m.\u001b[39mfill(value)\n\u001b[1;32m   2331\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2332\u001b[0m \n\u001b[1;32m   2333\u001b[0m         \u001b[38;5;66;03m# ensure array is contiguous\u001b[39;00m\n\u001b[0;32m-> 2334\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2337\u001b[0m     \u001b[38;5;66;03m# partially replace the contents of this chunk\u001b[39;00m\n\u001b[1;32m   2339\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2340\u001b[0m \n\u001b[1;32m   2341\u001b[0m         \u001b[38;5;66;03m# obtain compressed data for chunk\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_convert(\"dataset/collected_single/constant.zarr\")  \n",
    "dataset_convert(\"dataset/collected_single_short/constant.zarr\")\n",
    "dataset_convert(\"dataset/collected_trajectories_v2/constant.zarr\")\n",
    "dataset_convert(\"dataset/collected_trajectories_v2/switch.zarr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec77e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      " ├── data\n",
      " │   ├── actions (125000, 19) float32\n",
      " │   ├── clock (125000, 5, 2) float32\n",
      " │   ├── commands (125000, 5, 11) float32\n",
      " │   ├── critic_obs (16000, 321) float32\n",
      " │   ├── dones (125000,) bool\n",
      " │   ├── proprio (16125, 5, 63) float32\n",
      " │   ├── rewards (125000,) float32\n",
      " │   └── root_states (125000, 13) float32\n",
      " └── meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/123 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/123 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "BoundsCheckError",
     "evalue": "index out of bounds for dimension with length Caught BoundsCheckError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_120271/1397987268.py\", line 21, in __getitem__\n    return {key: self.data_dict[key][idx] for key in self.data_dict.keys()}\n  File \"/tmp/ipykernel_120271/1397987268.py\", line 21, in <dictcomp>\n    return {key: self.data_dict[key][idx] for key in self.data_dict.keys()}\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py\", line 844, in __getitem__\n    result = self.get_basic_selection(pure_selection, fields=fields)\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py\", line 970, in get_basic_selection\n    return self._get_basic_selection_nd(selection=selection, out=out, fields=fields)\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py\", line 1010, in _get_basic_selection_nd\n    indexer = BasicIndexer(selection, self)\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/indexing.py\", line 342, in __init__\n    dim_indexer = IntDimIndexer(dim_sel, dim_len, dim_chunk_len)\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/indexing.py\", line 150, in __init__\n    dim_sel = normalize_integer_selection(dim_sel, dim_len)\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/indexing.py\", line 124, in normalize_integer_selection\n    raise BoundsCheckError(dim_len)\nzarr.errors.BoundsCheckError: index out of bounds for dimension with length 16125\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBoundsCheckError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(dataloader)\n\u001b[1;32m     29\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pbar):\n\u001b[1;32m     31\u001b[0m     time_taken \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     32\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime per batch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_taken\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1370\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/hugwbc/lib/python3.8/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mBoundsCheckError\u001b[0m: index out of bounds for dimension with length Caught BoundsCheckError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_120271/1397987268.py\", line 21, in __getitem__\n    return {key: self.data_dict[key][idx] for key in self.data_dict.keys()}\n  File \"/tmp/ipykernel_120271/1397987268.py\", line 21, in <dictcomp>\n    return {key: self.data_dict[key][idx] for key in self.data_dict.keys()}\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py\", line 844, in __getitem__\n    result = self.get_basic_selection(pure_selection, fields=fields)\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py\", line 970, in get_basic_selection\n    return self._get_basic_selection_nd(selection=selection, out=out, fields=fields)\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/core.py\", line 1010, in _get_basic_selection_nd\n    indexer = BasicIndexer(selection, self)\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/indexing.py\", line 342, in __init__\n    dim_indexer = IntDimIndexer(dim_sel, dim_len, dim_chunk_len)\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/indexing.py\", line 150, in __init__\n    dim_sel = normalize_integer_selection(dim_sel, dim_len)\n  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/zarr/indexing.py\", line 124, in normalize_integer_selection\n    raise BoundsCheckError(dim_len)\nzarr.errors.BoundsCheckError: index out of bounds for dimension with length 16125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-32:\n",
      "Process Process-29:\n",
      "Process Process-31:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/root/miniconda3/envs/hugwbc/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from legged_gym.dataset.replay_buffer import ReplayBuffer\n",
    "import numpy as np\n",
    "\n",
    "class RBDataset(Dataset):\n",
    "    def __init__(self, rb_path):\n",
    "        self.rb = ReplayBuffer.create_from_path(rb_path)\n",
    "        print(self.rb)\n",
    "        self.data_dict = {}\n",
    "        preload_keys = [\"actions\", \"commands\"]\n",
    "        disk_keys = [\"proprio\", \"critic_obs\"]\n",
    "        for key in preload_keys:\n",
    "            self.data_dict[key] = self.rb.data[key][:]\n",
    "        for key in disk_keys:\n",
    "            self.data_dict[key] = self.rb.data[key]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_dict['actions'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: self.data_dict[key][idx] for key in self.data_dict.keys()}\n",
    "\n",
    "rb_dataset = RBDataset(\"dataset/small_chunk4kb/constant.zarr\")\n",
    "# print(rb_dataset[0])\n",
    "dataloader = DataLoader(rb_dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
    "import tqdm\n",
    "import time\n",
    "pbar = tqdm.tqdm(dataloader)\n",
    "start_time = time.time()\n",
    "for idx, batch in enumerate(pbar):\n",
    "    time_taken = time.time() - start_time\n",
    "    pbar.set_description(f\"time per batch: {time_taken / (idx + 1):.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2aeb6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from legged_gym.dataset.replay_buffer import ReplayBuffer\n",
    "import numpy as np\n",
    "\n",
    "class RBDataset(Dataset):\n",
    "    def __init__(self, rb_path):\n",
    "        self.rb = ReplayBuffer.create_from_path(rb_path)\n",
    "        self.data_dict = {}\n",
    "        preload_keys = [\"actions\", \"commands\"]\n",
    "        disk_keys = [\"proprio\", \"critic_obs\"]\n",
    "        preload_keys.extend(disk_keys)\n",
    "        for key in disk_keys:\n",
    "            self.data_dict[key] = self.rb.data[key]\n",
    "        for key in preload_keys:\n",
    "            self.data_dict[key] = self.rb.data[key][:]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_dict['actions'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: self.data_dict[key][idx] for key in self.data_dict.keys()}\n",
    "\n",
    "# rb_dataset = RBDataset(\"dataset/small_chunk_large/constant.zarr\")\n",
    "rb = ReplayBuffer.create_from_path(\"dataset/small_chunk_large/constant.zarr\")\n",
    "# print(rb_dataset[0])\n",
    "# dataloader = DataLoader(rb_dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
    "# import tqdm\n",
    "# import time\n",
    "# pbar = tqdm.tqdm(dataloader)\n",
    "# start_time = time.time()\n",
    "# for idx, batch in enumerate(pbar):\n",
    "#     time_taken = time.time() - start_time\n",
    "#     pbar.set_description(f\"time per batch: {time_taken / (idx + 1):.3f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74ccb826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 63)\n",
      "(321,)\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "proprio_dim = 44\n",
    "action_dim = 19\n",
    "cmd_dim = 11\n",
    "clock_dim = 2\n",
    "privileged_dim = 24\n",
    "terrain_dim = 221\n",
    "\n",
    "obs = rb.data['proprio'][1]\n",
    "critic_obs = rb.data['critic_obs'][1]\n",
    "action = rb.data['actions'][0]\n",
    "cmd = rb.data['commands'][1]\n",
    "print(obs.shape)\n",
    "print(critic_obs.shape)\n",
    "print(np.all((obs[-1, :proprio_dim] - critic_obs[:proprio_dim]) < 1e-6))\n",
    "print(np.all((obs[-1, proprio_dim:proprio_dim + action_dim] - action) < 1e-6))\n",
    "print(np.all((cmd[-1] - critic_obs[proprio_dim + action_dim:proprio_dim + action_dim + cmd_dim]) < 1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f4ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from legged_gym.dataset.replay_buffer import ReplayBuffer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def dataset_repair(raw_dataset_path):\n",
    "    repaired_path = raw_dataset_path.replace(\".zarr\", \"_repaired.zarr\")\n",
    "    if os.path.exists(repaired_path):\n",
    "        shutil.rmtree(repaired_path)\n",
    "    repaired_rb = ReplayBuffer.create_empty_zarr(repaired_path)\n",
    "    rb = ReplayBuffer.create_from_path(raw_dataset_path)\n",
    "    print(rb)\n",
    "    rb_data = {key: rb.data[key][:] for key in rb.data.keys()}\n",
    "    meta_data = {key: rb.meta[key][:] for key in rb.meta.keys()}\n",
    "    data_buffers = {key: [] for key in rb.data.keys()}\n",
    "    new_episode_ends = []\n",
    "    mis_matched_keys = set(['proprio', 'commands', 'clock', 'critic_obs', 'root_states'])\n",
    "    for ep_idx, ep_ends in tqdm(enumerate(rb.meta.episode_ends)):\n",
    "        if ep_idx == 0:\n",
    "            ep_start = 0\n",
    "        else:\n",
    "            ep_start = rb.meta.episode_ends[ep_idx - 1]\n",
    "        ep_end = rb.meta.episode_ends[ep_idx]\n",
    "        ep_len = ep_end - ep_start\n",
    "        if len(new_episode_ends) == 0:\n",
    "            new_episode_ends.append(ep_len - 1)\n",
    "        else:\n",
    "            new_episode_ends.append(new_episode_ends[-1] + ep_len - 1)\n",
    "        ep_data = {}\n",
    "        for key in rb_data.keys():\n",
    "            if key not in mis_matched_keys:\n",
    "                ep_data[key] = rb_data[key][ep_start:ep_end][1:]\n",
    "            else:\n",
    "                ep_data[key] = rb_data[key][ep_start:ep_end][:-1]\n",
    "        for key, val in ep_data.items():\n",
    "            data_buffers[key].append(val)\n",
    "        assert ep_len - 1 == len(ep_data['actions'])\n",
    "        if (ep_idx + 1) % 1000 == 0:\n",
    "            # print(f\"Processed {ep_idx + 1} episodes, saving to {repaired_path}\")\n",
    "            for key, val in data_buffers.items():\n",
    "                data_buffers[key] = np.concatenate(val, axis=0)\n",
    "            repaired_rb.add_chunked_data(data_buffers, target_chunk_bytes=1024 * 1024 * 1024 * 2)\n",
    "            data_buffers = {key: [] for key in rb.data.keys()}\n",
    "    if len(data_buffers['actions']) > 0:\n",
    "        for key, val in data_buffers.items():\n",
    "            data_buffers[key] = np.concatenate(val, axis=0)\n",
    "        repaired_rb.add_chunked_data(data_buffers, target_chunk_bytes=1024 * 1024 * 1024 * 2)\n",
    "    meta_data['episode_ends'] = np.array(new_episode_ends)\n",
    "    repaired_rb.add_chunked_meta(meta_data, target_chunk_bytes=1024 * 1024 * 1024 * 2)\n",
    "    print(repaired_rb)\n",
    "    return repaired_rb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183ec6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from legged_gym.dataset.replay_buffer import ReplayBuffer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def dataset_transfer_chunked(raw_dataset_path):\n",
    "    repaired_path = raw_dataset_path.replace(\".zarr\", \"_transferred.zarr\")\n",
    "    if os.path.exists(repaired_path):\n",
    "        shutil.rmtree(repaired_path)\n",
    "    repaired_rb = ReplayBuffer.create_empty_zarr(repaired_path)\n",
    "    rb = ReplayBuffer.create_from_path(raw_dataset_path)\n",
    "    print(rb)\n",
    "    save_interval = 1000\n",
    "    meta_data = {key: rb.meta[key][:] for key in rb.meta.keys()}\n",
    "    large_keys = set(['proprio', 'critic_obs'])\n",
    "    for ep_idx in tqdm(range(0, len(rb.meta.episode_ends), save_interval)):\n",
    "        pre_load_start = 0 if ep_idx == 0 else rb.meta.episode_ends[ep_idx - 1]\n",
    "        pre_load_end = rb.meta.episode_ends[ep_idx + save_interval - 1]\n",
    "        rb_data = {key: rb.data[key][pre_load_start:pre_load_end] for key in rb.data.keys()}\n",
    "        ep_data = {}\n",
    "        large_ep_data = {}\n",
    "        for key in rb_data.keys():\n",
    "            if key not in large_keys:\n",
    "                ep_data[key] = rb_data[key]\n",
    "            else:\n",
    "                large_ep_data[key] = rb_data[key]\n",
    "        repaired_rb.add_chunked_data_encoded(ep_data, target_chunk_bytes=1024 * 1024 * 1024 * 2)\n",
    "        repaired_rb.add_chunked_data_encoded(large_ep_data, storage=\"sharded\")   \n",
    "    repaired_rb.add_chunked_meta_encoded(meta_data, target_chunk_bytes=1024 * 1024 * 1024 * 1024 * 2)\n",
    "    print(repaired_rb)\n",
    "    return repaired_rb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb0d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      " ├── data\n",
      " │   ├── actions (81784864, 19) float32\n",
      " │   ├── clock (81784864, 5, 2) float32\n",
      " │   ├── commands (81784864, 5, 11) float32\n",
      " │   ├── critic_obs (81784864, 321) float32\n",
      " │   ├── dones (81784864,) bool\n",
      " │   ├── proprio (81784864, 5, 63) float32\n",
      " │   ├── rewards (81784864,) float32\n",
      " │   └── root_states (81784864, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command (164000, 11) float32\n",
      "     ├── episode_ends (164000,) int64\n",
      "     └── episode_reward (164000,) float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/164 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot import name 'ShardingCodec' from 'numcodecs' (/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/numcodecs/__init__.py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Requested storage='sharded' but numcodecs.ShardingCodec is unavailable (need numcodecs>=0.11). Try `pip install -U numcodecs` or use storage='zstd_bitshuffle'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/cpfs/user/caozhe/workspace/HugWBC/legged_gym/dataset/replay_buffer.py:530\u001b[0m, in \u001b[0;36mReplayBuffer._make_storage_compressor\u001b[0;34m(self, storage, chunks, zstd_level, use_bitshuffle, shard_time)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumcodecs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShardingCodec\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ShardingCodec' from 'numcodecs' (/root/miniconda3/envs/hugwbc/lib/python3.8/site-packages/numcodecs/__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset_transfer_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollected_large/constant.zarr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m dataset_transfer_chunked(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollected_large/switch.zarr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m, in \u001b[0;36mdataset_transfer_chunked\u001b[0;34m(raw_dataset_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m             large_ep_data[key] \u001b[38;5;241m=\u001b[39m rb_data[key]\n\u001b[1;32m     28\u001b[0m     repaired_rb\u001b[38;5;241m.\u001b[39madd_chunked_data_encoded(ep_data, target_chunk_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mrepaired_rb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_chunked_data_encoded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlarge_ep_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharded\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     30\u001b[0m repaired_rb\u001b[38;5;241m.\u001b[39madd_chunked_meta_encoded(meta_data, target_chunk_bytes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(repaired_rb)\n",
      "File \u001b[0;32m/cpfs/user/caozhe/workspace/HugWBC/legged_gym/dataset/replay_buffer.py:653\u001b[0m, in \u001b[0;36mReplayBuffer.add_chunked_data_encoded\u001b[0;34m(self, data, storage, chunks, zstd_level, use_bitshuffle, shard_time, target_chunk_bytes)\u001b[0m\n\u001b[1;32m    651\u001b[0m         cks \u001b[38;5;241m=\u001b[39m get_optimal_chunks(shape\u001b[38;5;241m=\u001b[39mnew_shape, dtype\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdtype, target_chunk_bytes\u001b[38;5;241m=\u001b[39mtarget_chunk_bytes)\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;66;03m# compressor by storage\u001b[39;00m\n\u001b[0;32m--> 653\u001b[0m     cpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_storage_compressor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzstd_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzstd_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_bitshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_bitshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshard_time\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mzeros(name\u001b[38;5;241m=\u001b[39mkey, shape\u001b[38;5;241m=\u001b[39mnew_shape, chunks\u001b[38;5;241m=\u001b[39mcks, dtype\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdtype, compressor\u001b[38;5;241m=\u001b[39mcpr)\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/cpfs/user/caozhe/workspace/HugWBC/legged_gym/dataset/replay_buffer.py:533\u001b[0m, in \u001b[0;36mReplayBuffer._make_storage_compressor\u001b[0;34m(self, storage, chunks, zstd_level, use_bitshuffle, shard_time)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested storage=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msharded\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but numcodecs.ShardingCodec is unavailable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(need numcodecs>=0.11). Try `pip install -U numcodecs` or use storage=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzstd_bitshuffle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    536\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# inner codec：zstd(+bitshuffle) via Blosc（兼容性最好）\u001b[39;00m\n\u001b[1;32m    538\u001b[0m shuffle \u001b[38;5;241m=\u001b[39m numcodecs\u001b[38;5;241m.\u001b[39mBlosc\u001b[38;5;241m.\u001b[39mBITSHUFFLE \u001b[38;5;28;01mif\u001b[39;00m use_bitshuffle \u001b[38;5;28;01melse\u001b[39;00m numcodecs\u001b[38;5;241m.\u001b[39mBlosc\u001b[38;5;241m.\u001b[39mNOSHUFFLE\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Requested storage='sharded' but numcodecs.ShardingCodec is unavailable (need numcodecs>=0.11). Try `pip install -U numcodecs` or use storage='zstd_bitshuffle'."
     ]
    }
   ],
   "source": [
    "dataset_transfer_chunked(\"collected_large/constant.zarr\")\n",
    "dataset_transfer_chunked(\"collected_large/switch.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d34b956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_scales = np.array(\n",
    "    [2, 2, 0.25, 1, 1, 1, 0.15, 2.0, 0.5, 0.5, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8751e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proprio [-8.2740314e-02  1.2649980e-01  1.4966875e-01  1.6320884e-02\n",
      " -1.5481804e-03 -1.0315908e+00  7.1848519e-03  7.0408601e-03\n",
      "  1.3767800e-01  4.2155340e-02 -7.5490206e-02  2.3022011e-02\n",
      "  1.5871401e-04 -6.4363830e-02  2.0078197e-02  2.5046857e-02\n",
      " -1.2482957e-02  3.1448044e-02  3.2764327e-02  2.1609386e-02\n",
      " -6.0810940e-04 -1.3010241e-02 -3.2440796e-02  1.4345683e-02\n",
      "  2.9225057e-02  4.2959228e-02 -7.5227008e-03 -1.3294491e-01\n",
      "  6.4396299e-02 -1.3069978e-01  4.2481008e-03 -4.0397819e-02\n",
      "  6.8747178e-02 -1.1066597e-01 -1.1843402e-01 -3.3626080e-02\n",
      "  2.8691573e-02  6.9325961e-02  6.8520859e-02 -4.7457766e-02\n",
      " -2.6354637e-02 -4.9802817e-02 -1.8618196e-02 -2.5761236e-02]\n",
      "history_action [ 0.31945917  0.04709061  0.11344864 -0.43507007 -0.9177139   0.18261054\n",
      "  0.21388778  0.2092223   0.29703414 -0.70665544 -0.33453184  0.9841815\n",
      "  0.3678542   0.16917886 -0.2781665   0.49742576 -0.23865336 -0.00202002\n",
      " -0.26939726]\n",
      "commands [ 1.0143085  -0.19354099 -0.085485    2.9061322   0.          0.5\n",
      "  0.0375139  -0.02313649  0.07109034 -0.15010631  0.        ]\n",
      "commands [ 1.0143085  -0.19354099 -0.085485    2.9061322   0.          0.5\n",
      "  0.0375139  -0.02313649  0.07109034 -0.15010631  0.        ]\n",
      "clock [0.8655097 0.8655097]\n",
      "Actual commands [-0.47692707  0.2385202   0.          2.5704217   0.5         0.5\n",
      "  0.3028947  -0.02649801  0.21525608 -0.37351966  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"proprio\", rb.data['proprio'][0, -1])\n",
    "print(\"history_action\", rb.data['history_action'][0, -1])\n",
    "print(\"commands\", rb.data['commands'][0, -1])\n",
    "print(\"commands\", rb.data['commands'][0, -2])\n",
    "print(\"clock\", rb.data['clock'][0, -1])\n",
    "print(\"Actual commands\", rb.meta['episode_command_A'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe3564c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.95385414  0.47704041  0.          2.5704217   0.5         0.5\n",
      "  0.04543421 -0.05299602  0.10762804 -0.18675983  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(rb.meta['episode_command_A'][0] * command_scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a02adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      " ├── data\n",
      " │   ├── actions (9995546, 19) float32\n",
      " │   ├── clock (9995546, 5, 2) float32\n",
      " │   ├── commands (9995546, 5, 11) float32\n",
      " │   ├── critic_obs (9995546, 321) float32\n",
      " │   ├── dones (9995546,) bool\n",
      " │   ├── proprio (9995546, 5, 63) float32\n",
      " │   ├── rewards (9995546,) float32\n",
      " │   └── root_states (9995546, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command (20000, 11) float32\n",
      "     ├── episode_ends (20000,) int64\n",
      "     └── episode_reward (20000,) float32\n"
     ]
    }
   ],
   "source": [
    "from legged_gym.dataset.replay_buffer import ReplayBuffer\n",
    "import numpy as np\n",
    "\n",
    "rb = ReplayBuffer.create_from_path(\"/root/workspace/HugWBC/collected_trajectories_v2/constant.zarr\", mode='a')\n",
    "print(rb)\n",
    "# print(rb.meta.episode_reward[:].max())\n",
    "# print(rb.meta.episode_reward[:].min())\n",
    "# print(rb.meta.episode_reward[:].mean())\n",
    "# print(rb.meta.episode_reward[:].std())\n",
    "# episode_ends = rb.meta.episode_ends[:]\n",
    "# rb.new_meta_key(\"episode_ends_new\", shape=(0,), dtype=np.int64, compressor=None, overwrite=False)\n",
    "# rb.add_chunked_meta({\"episode_ends_new\": episode_ends}, target_chunk_bytes=1024 * 1024 * 1024 * 2)\n",
    "# import numpy as np\n",
    "# rb.new_meta_key(\"episode_ends_new\", shape=(0,), dtype=np.int64, compressor=None, overwrite=False)\n",
    "# rb.add_chunked_meta({\"episode_ends_new\": episode_ends}, target_chunk_bytes=1024 * 1024 * 1024 * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b259b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   500,   1000,   1500,   2000,   2500,   3000,   3500,   4000,\n",
       "         4500,   5000,   5500,   6000,   6500,   7000,   7500,   8000,\n",
       "         8500,   9000,   9500,  10000,  10500,  11000,  11500,  12000,\n",
       "        12500,  13000,  13500,  14000,  14500,  15000,  15500,  16000,\n",
       "        16500,  17000,  17500,  18000,  18500,  19000,  19500,  20000,\n",
       "        20500,  21000,  21500,  22000,  22500,  23000,  23500,  24000,\n",
       "        24500,  25000,  25500,  26000,  26500,  27000,  27500,  28000,\n",
       "        28500,  29000,  29500,  30000,  30500,  31000,  31500,  32000,\n",
       "        32500,  33000,  33500,  34000,  34500,  35000,  35500,  36000,\n",
       "        36500,  37000,  37500,  38000,  38500,  39000,  39500,  40000,\n",
       "        40500,  41000,  41500,  42000,  42500,  43000,  43500,  44000,\n",
       "        44500,  45000,  45500,  46000,  46500,  47000,  47500,  48000,\n",
       "        48500,  49000,  49500,  50000,  50500,  51000,  51500,  52000,\n",
       "        52500,  53000,  53500,  54000,  54500,  55000,  55500,  56000,\n",
       "        56500,  57000,  57500,  58000,  58500,  59000,  59500,  60000,\n",
       "        60500,  61000,  61500,  62000,  62500,  63000,  63500,  64000,\n",
       "        64500,  65000,  65500,  66000,  66500,  67000,  67500,  68000,\n",
       "        68500,  69000,  69500,  70000,  70500,  71000,  71500,  72000,\n",
       "        72500,  73000,  73500,  74000,  74500,  75000,  75500,  76000,\n",
       "        76500,  77000,  77500,  78000,  78500,  79000,  79500,  80000,\n",
       "        80500,  81000,  81500,  82000,  82500,  83000,  83500,  84000,\n",
       "        84500,  85000,  85500,  86000,  86500,  87000,  87500,  88000,\n",
       "        88500,  89000,  89500,  90000,  90500,  91000,  91500,  92000,\n",
       "        92500,  93000,  93500,  94000,  94500,  95000,  95500,  96000,\n",
       "        96500,  97000,  97500,  98000,  98500,  99000,  99500, 100000,\n",
       "       100500, 101000, 101500, 102000, 102500, 103000, 103500, 104000,\n",
       "       104500, 105000, 105500, 106000, 106500, 107000, 107500, 108000,\n",
       "       108500, 109000, 109500, 110000, 110500, 111000, 111500, 112000,\n",
       "       112500, 113000, 113500, 114000, 114500, 115000, 115500, 116000,\n",
       "       116500, 117000, 117500, 118000, 118500, 119000, 119500, 120000,\n",
       "       120500, 121000, 121500, 122000, 122500, 123000, 123500, 124000,\n",
       "       124500, 125000, 125500, 126000, 126500, 127000, 127500, 128000,\n",
       "       128500, 129000, 129500, 130000, 130500, 131000, 131500, 132000,\n",
       "       132500, 133000, 133500, 134000, 134500, 135000, 135500, 136000,\n",
       "       136500, 137000, 137500, 138000, 138500, 139000, 139500, 140000,\n",
       "       140500, 141000, 141500, 142000, 142500, 143000, 143500, 144000,\n",
       "       144500, 145000, 145500, 146000, 146500, 147000, 147500, 148000,\n",
       "       148500, 149000, 149500, 150000, 150500, 151000, 151500, 152000,\n",
       "       152500, 153000, 153500, 154000, 154500, 155000, 155500, 156000,\n",
       "       156500, 157000, 157500, 158000, 158500, 159000, 159500, 160000,\n",
       "       160500, 161000, 161500, 162000, 162500, 163000, 163500, 164000,\n",
       "       164500, 165000, 165500, 166000, 166500, 167000, 167500, 168000,\n",
       "       168500, 169000, 169500, 170000, 170500, 171000, 171500, 172000,\n",
       "       172500, 173000, 173500, 174000, 174500, 175000, 175500, 176000,\n",
       "       176500, 177000, 177500, 178000, 178500, 179000, 179500, 180000,\n",
       "       180500, 181000, 181500, 182000, 182500, 183000, 183500, 184000,\n",
       "       184500, 185000, 185500, 186000, 186500, 187000, 187500, 188000,\n",
       "       188500, 189000, 189500, 190000, 190500, 191000, 191500, 192000,\n",
       "       192500, 193000, 193500, 194000, 194500, 195000, 195500, 196000,\n",
       "       196500, 197000, 197500, 198000, 198500, 199000, 199500, 200000,\n",
       "       200500, 201000, 201500, 202000, 202500, 203000, 203500, 204000,\n",
       "       204500, 205000, 205500, 206000, 206500, 207000, 207500, 208000,\n",
       "       208500, 209000, 209500, 210000, 210500, 211000, 211500, 212000,\n",
       "       212500, 213000, 213500, 214000, 214500, 215000, 215500, 216000,\n",
       "       216500, 217000, 217500, 218000, 218500, 219000, 219500, 220000,\n",
       "       220500, 221000, 221500, 222000, 222500, 223000, 223500, 224000,\n",
       "       224500, 225000, 225500, 226000, 226500, 227000, 227500, 228000,\n",
       "       228500, 229000, 229500, 230000, 230500, 231000, 231500, 232000,\n",
       "       232500, 233000, 233500, 234000, 234500, 235000, 235500, 236000,\n",
       "       236500, 237000, 237500, 238000, 238500, 239000, 239500, 240000,\n",
       "       240500, 241000, 241500, 242000, 242500, 243000, 243500, 244000,\n",
       "       244500, 245000, 245500, 246000, 246500, 247000, 247500, 248000,\n",
       "       248500, 249000, 249500, 250000, 250500, 251000, 251500, 252000,\n",
       "       252500, 253000, 253500, 254000, 254500, 255000, 255500, 256000,\n",
       "       256500, 257000, 257500, 258000, 258500, 259000, 259500, 260000,\n",
       "       260500, 261000, 261500, 262000, 262500, 263000, 263500, 264000,\n",
       "       264500, 265000, 265500, 266000, 266500, 267000, 267500, 268000,\n",
       "       268500, 269000, 269500, 270000, 270500, 271000, 271500, 272000,\n",
       "       272500, 273000, 273500, 274000, 274500, 275000, 275500, 276000,\n",
       "       276500, 277000, 277500, 278000, 278500, 279000, 279500, 280000,\n",
       "       280500, 281000, 281500, 282000, 282500, 283000, 283500, 284000,\n",
       "       284500, 285000, 285500, 286000, 286500, 287000, 287500, 288000,\n",
       "       288500, 289000, 289500, 290000, 290500, 291000, 291500, 292000,\n",
       "       292500, 293000, 293500, 294000, 294500, 295000, 295500, 296000,\n",
       "       296500, 297000, 297500, 298000, 298500, 299000, 299500, 300000,\n",
       "       300500, 301000, 301500, 302000, 302500, 303000, 303500, 304000,\n",
       "       304500, 305000, 305500, 306000, 306500, 307000, 307500, 308000,\n",
       "       308500, 309000, 309500, 310000, 310500, 311000, 311500, 312000,\n",
       "       312500, 313000, 313500, 314000, 314500, 315000, 315500, 316000,\n",
       "       316500, 317000, 317500, 318000, 318500, 319000, 319500, 320000,\n",
       "       320500, 321000, 321500, 322000, 322500, 323000, 323500, 324000,\n",
       "       324500, 325000, 325500, 326000, 326500, 327000, 327500, 328000,\n",
       "       328500, 329000, 329500, 330000, 330500, 331000, 331500, 332000,\n",
       "       332500, 333000, 333500, 334000, 334500, 335000, 335500, 336000,\n",
       "       336500, 337000, 337500, 338000, 338500, 339000, 339500, 340000,\n",
       "       340500, 341000, 341500, 342000, 342500, 343000, 343500, 344000,\n",
       "       344500, 345000, 345500, 346000, 346500, 347000, 347500, 348000,\n",
       "       348500, 349000, 349500, 350000, 350500, 351000, 351500, 352000,\n",
       "       352500, 353000, 353500, 354000, 354500, 355000, 355500, 356000,\n",
       "       356500, 357000, 357500, 358000, 358500, 359000, 359500, 360000,\n",
       "       360500, 361000, 361500, 362000, 362500, 363000, 363500, 364000,\n",
       "       364500, 365000, 365500, 366000, 366500, 367000, 367500, 368000,\n",
       "       368500, 369000, 369500, 370000, 370500, 371000, 371500, 372000,\n",
       "       372500, 373000, 373500, 374000, 374500, 375000, 375500, 376000,\n",
       "       376500, 377000, 377500, 378000, 378500, 379000, 379500, 380000,\n",
       "       380500, 381000, 381500, 382000, 382500, 383000, 383500, 384000,\n",
       "       384500, 385000, 385500, 386000, 386500, 387000, 387500, 388000,\n",
       "       388500, 389000, 389500, 390000, 390500, 391000, 391500, 392000,\n",
       "       392500, 393000, 393500, 394000, 394500, 395000, 395500, 396000,\n",
       "       396500, 397000, 397500, 398000, 398500, 399000, 399500, 400000,\n",
       "       400500, 401000, 401500, 402000, 402500, 403000, 403500, 404000,\n",
       "       404500, 405000, 405500, 406000, 406500, 407000, 407500, 408000,\n",
       "       408500, 409000, 409500, 410000, 410500, 411000, 411500, 412000,\n",
       "       412500, 413000, 413500, 414000, 414500, 415000, 415500, 416000,\n",
       "       416500, 417000, 417500, 418000, 418500, 419000, 419500, 420000,\n",
       "       420500, 421000, 421500, 422000, 422500, 423000, 423500, 424000,\n",
       "       424500, 425000, 425500, 426000, 426500, 427000, 427500, 428000,\n",
       "       428500, 429000, 429500, 430000, 430500, 431000, 431500, 432000,\n",
       "       432500, 433000, 433500, 434000, 434500, 435000, 435500, 436000,\n",
       "       436500, 437000, 437500, 438000, 438500, 439000, 439500, 440000,\n",
       "       440500, 441000, 441500, 442000, 442500, 443000, 443500, 444000,\n",
       "       444500, 445000, 445500, 446000, 446500, 447000, 447500, 448000,\n",
       "       448500, 449000, 449500, 450000, 450500, 451000, 451500, 452000,\n",
       "       452500, 453000, 453500, 454000, 454500, 455000, 455500, 456000,\n",
       "       456500, 457000, 457500, 458000, 458500, 459000, 459500, 460000,\n",
       "       460500, 461000, 461500, 462000, 462500, 463000, 463500, 464000,\n",
       "       464500, 465000, 465500, 466000, 466500, 467000, 467500, 468000,\n",
       "       468500, 469000, 469500, 470000, 470500, 471000, 471500, 472000,\n",
       "       472500, 473000, 473500, 474000, 474500, 475000, 475500, 476000,\n",
       "       476500, 477000, 477500, 478000, 478500, 479000, 479500, 480000,\n",
       "       480500, 481000, 481500, 482000, 482500, 483000, 483500, 484000,\n",
       "       484500, 485000, 485500, 486000, 486500, 487000, 487500, 488000,\n",
       "       488500, 489000, 489500, 490000, 490500, 491000, 491500, 492000,\n",
       "       492500, 493000, 493500, 494000, 494500, 495000, 495500, 496000,\n",
       "       496500, 497000, 497500, 498000, 498500, 499000, 499500, 500000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb.episode_ends[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9443d943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      " ├── data\n",
      " │   ├── actions (3438, 19) float32\n",
      " │   ├── clock (3438, 5, 2) float32\n",
      " │   ├── commands (3438, 5, 11) float32\n",
      " │   ├── critic_obs (3438, 321) float32\n",
      " │   ├── dones (3438,) bool\n",
      " │   ├── proprio (3438, 5, 63) float32\n",
      " │   ├── rewards (3438,) float32\n",
      " │   └── root_states (3438, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command_A (10, 10) float64\n",
      "     ├── episode_ends (10,) int64\n",
      "     └── episode_reward (10,) float64\n",
      "/\n",
      " ├── data\n",
      " │   ├── actions (4682, 19) float32\n",
      " │   ├── clock (4682, 5, 2) float32\n",
      " │   ├── commands (4682, 5, 11) float32\n",
      " │   ├── critic_obs (4682, 321) float32\n",
      " │   ├── dones (4682,) bool\n",
      " │   ├── proprio (4682, 5, 63) float32\n",
      " │   ├── rewards (4682,) float32\n",
      " │   └── root_states (4682, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command_A (10, 10) float64\n",
      "     ├── episode_ends (10,) int64\n",
      "     └── episode_reward (10,) float64\n",
      "/\n",
      " ├── data\n",
      " │   ├── actions (4822, 19) float32\n",
      " │   ├── clock (4822, 5, 2) float32\n",
      " │   ├── commands (4822, 5, 11) float32\n",
      " │   ├── critic_obs (4822, 321) float32\n",
      " │   ├── dones (4822,) bool\n",
      " │   ├── proprio (4822, 5, 63) float32\n",
      " │   ├── rewards (4822,) float32\n",
      " │   └── root_states (4822, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command_A (10, 10) float64\n",
      "     ├── episode_ends (10,) int64\n",
      "     └── episode_reward (10,) float64\n",
      "/\n",
      " ├── data\n",
      " │   ├── actions (2922, 19) float32\n",
      " │   ├── clock (2922, 5, 2) float32\n",
      " │   ├── commands (2922, 5, 11) float32\n",
      " │   ├── critic_obs (2922, 321) float32\n",
      " │   ├── dones (2922,) bool\n",
      " │   ├── proprio (2922, 5, 63) float32\n",
      " │   ├── rewards (2922,) float32\n",
      " │   └── root_states (2922, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command_A (10, 10) float64\n",
      "     ├── episode_ends (10,) int64\n",
      "     └── episode_reward (10,) float64\n",
      "/\n",
      " ├── data\n",
      " │   ├── actions (5000, 19) float32\n",
      " │   ├── clock (5000, 5, 2) float32\n",
      " │   ├── commands (5000, 5, 11) float32\n",
      " │   ├── critic_obs (5000, 321) float32\n",
      " │   ├── dones (5000,) bool\n",
      " │   ├── proprio (5000, 5, 63) float32\n",
      " │   ├── rewards (5000,) float32\n",
      " │   └── root_states (5000, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command_A (10, 10) float64\n",
      "     ├── episode_ends (10,) int64\n",
      "     └── episode_reward (10,) float64\n",
      "/\n",
      " ├── data\n",
      " │   ├── actions (5000, 19) float32\n",
      " │   ├── clock (5000, 5, 2) float32\n",
      " │   ├── commands (5000, 5, 11) float32\n",
      " │   ├── critic_obs (5000, 321) float32\n",
      " │   ├── dones (5000,) bool\n",
      " │   ├── proprio (5000, 5, 63) float32\n",
      " │   ├── rewards (5000,) float32\n",
      " │   └── root_states (5000, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command_A (10, 10) float64\n",
      "     ├── episode_ends (10,) int64\n",
      "     └── episode_reward (10,) float64\n",
      "/\n",
      " ├── data\n",
      " │   ├── actions (4612, 19) float32\n",
      " │   ├── clock (4612, 5, 2) float32\n",
      " │   ├── commands (4612, 5, 11) float32\n",
      " │   ├── critic_obs (4612, 321) float32\n",
      " │   ├── dones (4612,) bool\n",
      " │   ├── proprio (4612, 5, 63) float32\n",
      " │   ├── rewards (4612,) float32\n",
      " │   └── root_states (4612, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command_A (10, 10) float64\n",
      "     ├── episode_ends (10,) int64\n",
      "     └── episode_reward (10,) float64\n",
      "/\n",
      " ├── data\n",
      " │   ├── actions (3187, 19) float32\n",
      " │   ├── clock (3187, 5, 2) float32\n",
      " │   ├── commands (3187, 5, 11) float32\n",
      " │   ├── critic_obs (3187, 321) float32\n",
      " │   ├── dones (3187,) bool\n",
      " │   ├── proprio (3187, 5, 63) float32\n",
      " │   ├── rewards (3187,) float32\n",
      " │   └── root_states (3187, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command_A (10, 10) float64\n",
      "     ├── episode_ends (10,) int64\n",
      "     └── episode_reward (10,) float64\n",
      "/\n",
      " ├── data\n",
      " │   ├── actions (3346, 19) float32\n",
      " │   ├── clock (3346, 5, 2) float32\n",
      " │   ├── commands (3346, 5, 11) float32\n",
      " │   ├── critic_obs (3346, 321) float32\n",
      " │   ├── dones (3346,) bool\n",
      " │   ├── proprio (3346, 5, 63) float32\n",
      " │   ├── rewards (3346,) float32\n",
      " │   └── root_states (3346, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command_A (10, 10) float64\n",
      "     ├── episode_ends (10,) int64\n",
      "     └── episode_reward (10,) float64\n",
      "/\n",
      " ├── data\n",
      " │   ├── actions (5000, 19) float32\n",
      " │   ├── clock (5000, 5, 2) float32\n",
      " │   ├── commands (5000, 5, 11) float32\n",
      " │   ├── critic_obs (5000, 321) float32\n",
      " │   ├── dones (5000,) bool\n",
      " │   ├── proprio (5000, 5, 63) float32\n",
      " │   ├── rewards (5000,) float32\n",
      " │   └── root_states (5000, 13) float32\n",
      " └── meta\n",
      "     ├── episode_command_A (10, 10) float64\n",
      "     ├── episode_ends (10,) int64\n",
      "     └── episode_reward (10,) float64\n"
     ]
    }
   ],
   "source": [
    "parent_path = \"/root/workspace/HugWBC/example_trajectories\"\n",
    "import os\n",
    "import shutil\n",
    "for dirn in os.listdir(parent_path):\n",
    "    if os.path.isdir(os.path.join(parent_path, dirn)):\n",
    "        # assert os.path.exists(os.path.join(parent_path, dirn, \"data\", \"obs\")), f\"obs not found in {os.path.join(parent_path, dirn)}\"\n",
    "        # shutil.rmtree(os.path.join(parent_path, dirn, \"data\", \"proprio\"))\n",
    "        # shutil.rmtree(os.path.join(parent_path, dirn, \"data\", \"history_action\"))\n",
    "        # os.rename(os.path.join(parent_path, dirn, \"data\", \"obs\"), os.path.join(parent_path, dirn, \"data\", \"proprio\"))\n",
    "        rb = ReplayBuffer.create_from_path(os.path.join(parent_path, dirn), mode='a')\n",
    "        # pure_prop = rb.data['proprio'][:]\n",
    "        # history_action = rb.data['history_action'][:]\n",
    "        # obs = np.concatenate([pure_prop, history_action], axis=-1)\n",
    "        # rb.add_chunked_data({\n",
    "        #     'obs': obs,\n",
    "        # }, target_chunk_bytes=1024 * 1024 * 1024 * 64)\n",
    "\n",
    "        print(rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db0337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugwbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
